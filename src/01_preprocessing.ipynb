{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "problemCsvList = glob(\"../Project_CodeNet/metadata/*.csv\")\n",
    "solutionFolderList = glob(\"../Project_CodeNet/data/*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(problemCsvList))\n",
    "print(len(solutionFolderList))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([val.split(\"/\")[-1].replace(\".csv\", \"\") for val in problemCsvList]) ^ set([val.split(\"/\")[-1] for val in solutionFolderList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"../Project_CodeNet/metadata/problem_list.csv\" in problemCsvList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problemListCsvDF =pd.read_csv(\"../Project_CodeNet/metadata/problem_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "from multiprocessing import Process, Lock\n",
    "from tqdm import tqdm\n",
    "def read_dic(path):\n",
    "    a_file = open(path, \"r\")\n",
    "    output = a_file.read()\n",
    "    return output\n",
    "\n",
    "def write(data, path):\n",
    "    a_file = open(path, \"w\")\n",
    "    json.dump(data, a_file)\n",
    "    a_file.close()\n",
    "\n",
    "submissions = {}\n",
    "    \n",
    "def process(id, lock):\n",
    "    location = \"../Project_CodeNet/metadata/\"+id+'.csv'\n",
    "    problem_df = pd.read_csv(location)\n",
    "    #print(problem_df.columns)\n",
    "    for inddex, row in tqdm(problem_df.iterrows()):\n",
    "        information_tuple = (row['submission_id'], row['date'],row['language'],row['original_language'], row['filename_ext'], row['status'])\n",
    "        lock.acquire()\n",
    "        if(row['user_id'] in submissions.keys()):\n",
    "            if(row['problem_id'] in submissions[row['user_id']].keys()):\n",
    "                submissions[row['user_id']][row['problem_id']].append(information_tuple)\n",
    "            else:\n",
    "                submissions[row['user_id']][row['problem_id']] = [information_tuple]\n",
    "        else:\n",
    "            submissions[row['user_id']] = {}\n",
    "            submissions[row['user_id']][row['problem_id']] = [information_tuple]\n",
    "        \n",
    "        lock.release()\n",
    "    #from pprint import pprint\n",
    "    #pprint(submissions)\n",
    "'''\n",
    "['submission_id', 'problem_id', 'user_id', 'date', 'language',\n",
    "       'original_language', 'filename_ext', 'status', 'cpu_time', 'memory',\n",
    "       'code_size', 'accuracy'],\n",
    "'''  \n",
    "\n",
    "lock = Lock()\n",
    "\n",
    "Parallel(n_jobs=36, prefer=\"threads\")(\n",
    "    delayed(process)(row['id'], lock) for index, row in problemListCsvDF.iterrows())\n",
    "'''\n",
    "for index, row in problemListCsvDF.iterrows():\n",
    "    print(index, row['id'])\n",
    "    process(row['id'])\n",
    "    break\n",
    "'''\n",
    "write(submissions, \"processed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for user in submissions:\n",
    "    for problem in submissions[user]:\n",
    "        cnt+=len(submissions[user][problem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "from multiprocessing import Process, Lock\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "data = getJsonData(\"processed.json\")\n",
    "ans = 0\n",
    "for user in tqdm(data.keys()):\n",
    "    for problem_id in data[user].keys():\n",
    "        ans+=len(data[user][problem_id])\n",
    "print(\"total data = \", ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "from codegen.preprocessing.lang_processors.java_processor import JavaProcessor\n",
    "from codegen.preprocessing.lang_processors.python_processor import PythonProcessor\n",
    "\n",
    "root_folder = \"../third_party\"\n",
    "jprocessor = JavaProcessor(root_folder=root_folder)\n",
    "pyprocessor = PythonProcessor(root_folder=root_folder)\n",
    "\n",
    "class Solution:\n",
    "    def __init__(\n",
    "            self,\n",
    "            source,\n",
    "            lang,\n",
    "            problem_id,\n",
    "            code_tokens,\n",
    "            functions_standalone=[],\n",
    "            functions_class=[],\n",
    "            submission_id=\"\",\n",
    "            verdict=\"\"\n",
    "    ):\n",
    "        self.source = source\n",
    "        self.lang = lang\n",
    "        self.problem_id = problem_id\n",
    "        self.code_tokens = code_tokens\n",
    "        self.submission_id = submission_id\n",
    "        self.functions_standalone = functions_standalone\n",
    "        self.functions_class = functions_class\n",
    "        self.verdict=verdict\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'source: ' + self.source + '\\n' + \\\n",
    "               'lang: ' + self.lang + '\\n' + \\\n",
    "               'problem_id: ' + self.problem_id + '\\n' + \\\n",
    "               'code: ' + self.code_tokens + '\\n' + \\\n",
    "               'submission_id: ' + self.submission_id + '\\n' + \\\n",
    "               'verdict: ' + self.verdict + '\\n'\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'source: ' + self.source + '\\n' + \\\n",
    "               'lang: ' + self.lang + '\\n' + \\\n",
    "               'problem_id: ' + self.problem_id + '\\n' + \\\n",
    "               'code: ' + self.code_tokens + '\\n' + \\\n",
    "               'submission_id: ' + self.submission_id + '\\n'+ \\\n",
    "               'verdict: ' + self.verdict + '\\n'\n",
    "    def toJSON(self):\n",
    "        return self.__dict__\n",
    "\n",
    "\n",
    "def calculate_similarity(code1_tokens, code2_tokens):\n",
    "    code1 = ' '.join(code1_tokens)\n",
    "    code2 = ' '.join(code2_tokens)\n",
    "    return SequenceMatcher(None, code1, code2).ratio()\n",
    "\n",
    "def write_output_to_file(problems, file_to_write):\n",
    "    mode = 'w'\n",
    "    if os.path.exists(file_to_write):\n",
    "        mode = 'a'\n",
    "        with open(file_to_write, mode, encoding='utf8') as fw:\n",
    "            fw.write('\\n')\n",
    "    with open(file_to_write, mode, encoding='utf8') as fw:\n",
    "        fw.write('\\n'.join([json.dumps(p) for p in problems]))\n",
    "\n",
    "\n",
    "\n",
    "def process_user(user_id):\n",
    "    java_solutions = []\n",
    "    python_solutions = []\n",
    "\n",
    "    for problem_id in data[user_id].keys():\n",
    "        submissions = data[user_id][problem_id]\n",
    "\n",
    "        acceptedJavaSolution = \"\"\n",
    "        closeJavaSolution = \"\"\n",
    "        acceptedPythonSolution = \"\"\n",
    "        closePythonSolution = \"\"\n",
    "\n",
    "        functions_standalone_py=[]\n",
    "        functions_class_py = []\n",
    "        functions_standalone_java=[]\n",
    "        functions_class_java = []\n",
    "\n",
    "        closeSubmissionIdpy = \"\"\n",
    "        closeSubmissionIdjava=\"\"\n",
    "        submission_id_py=\"\"\n",
    "        submission_id_java=\"\"\n",
    "        verdict_py=\"\"\n",
    "        verdict_java=\"\"\n",
    "\n",
    "        for submisson in submissions:\n",
    "            try:\n",
    "                if(submisson[2]==\"Java\"):\n",
    "                    if(submisson[5]==\"Accepted\"):\n",
    "                        solution_path = \"../Project_CodeNet/data/\"+problem_id+\"/Java/\"+submisson[0]+'.java'\n",
    "                        with open(solution_path, 'r', encoding='utf8') as f:\n",
    "                            code = f.read()\n",
    "                            acceptedJavaSolution = code[::]\n",
    "                            submission_id_java = submisson[0]\n",
    "                            code_tokens_java = jprocessor.tokenize_code(code)\n",
    "                            fn_standalone_java, fn_class_java = jprocessor.extract_functions(code_tokens_java)\n",
    "                            functions_standalone_java = [(jprocessor.get_function_name(fn), fn) for fn in fn_standalone_java]\n",
    "                            functions_class_java = [(jprocessor.get_function_name(fn), fn) for fn in fn_class_java]\n",
    "\n",
    "\n",
    "                if(submisson[2]==\"Python\"):\n",
    "                    if(submisson[5]==\"Accepted\"):\n",
    "                        solution_path = \"../Project_CodeNet/data/\"+problem_id+\"/Python/\"+submisson[0]+'.py'\n",
    "                        with open(solution_path, 'r', encoding='utf8') as f:\n",
    "                            code = f.read()\n",
    "                            acceptedPythonSolution = code[::]\n",
    "                            submission_id_py = submisson[0]\n",
    "                            code_tokens_py = pyprocessor.tokenize_code(code)\n",
    "                            fn_standalone_py, fn_class_py = pyprocessor.extract_functions(code_tokens_py)\n",
    "                            functions_standalone_py = [(pyprocessor.get_function_name(fn), fn) for fn in fn_standalone_py]\n",
    "                            functions_class_py = [(pyprocessor.get_function_name(fn), fn) for fn in fn_class_py]\n",
    "            except BaseException as error:\n",
    "                print(\"error for submission top problem id\",problem_id, submisson)\n",
    "                pass\n",
    "\n",
    "\n",
    "        java_min_distance = 999999\n",
    "        python_min_distance = 999999\n",
    "        \n",
    "        for submisson in submissions:\n",
    "            try:\n",
    "                if(submisson[2]==\"Java\"):\n",
    "                    if(submisson[5]!=\"Accepted\"):\n",
    "                        solution_path = \"../Project_CodeNet/data/\"+problem_id+\"/Java/\"+submisson[0]+'.java'\n",
    "                        with open(solution_path, 'r', encoding='utf8') as f:\n",
    "                            code = f.read()\n",
    "                            dis = calculate_similarity(code,acceptedJavaSolution)\n",
    "                            if(dis<java_min_distance):\n",
    "                                closeJavaSolution=code[::]\n",
    "                                java_min_distance = dis\n",
    "                                closeSubmissionIdjava = submisson[0]\n",
    "                                verdict_java=submisson[5]\n",
    "\n",
    "\n",
    "                if(submisson[2]==\"Python\"):\n",
    "                    if(submisson[5]!=\"Accepted\"):\n",
    "                        solution_path = \"../Project_CodeNet/data/\"+problem_id+\"/Python/\"+submisson[0]+'.py'\n",
    "                        with open(solution_path, 'r', encoding='utf8') as f:\n",
    "                            code = f.read()\n",
    "                            dis = calculate_similarity(code,acceptedPythonSolution)\n",
    "                            if(dis<python_min_distance):\n",
    "                                closePythonSolution=code[::]\n",
    "                                python_min_distance = dis\n",
    "                                closeSubmissionIdpy = submisson[0]\n",
    "                                verdict_py=submisson[5]\n",
    "            except BaseException as error:\n",
    "                print(\"error for submission \", submisson)\n",
    "                pass\n",
    "            \n",
    "        if(len(acceptedPythonSolution)*len(closePythonSolution)):  \n",
    "            python_solutions.append((Solution(\n",
    "                                        \"source\",\n",
    "                                        'python',\n",
    "                                        problem_id,\n",
    "                                        closePythonSolution,\n",
    "                                        functions_standalone_py,\n",
    "                                        functions_class_py,\n",
    "                                        closeSubmissionIdpy,\n",
    "                                        verdict_py\n",
    "                                    ).toJSON(),Solution(\n",
    "                                        \"source\",\n",
    "                                        'python',\n",
    "                                        problem_id,\n",
    "                                        acceptedPythonSolution,\n",
    "                                        functions_standalone_py,\n",
    "                                        functions_class_py,\n",
    "                                        submission_id_py,\n",
    "                                        \"Accepted\"\n",
    "                                    ).toJSON())\n",
    "                                )\n",
    "        if(len(acceptedJavaSolution)*len(closeJavaSolution)):\n",
    "            java_solutions.append((Solution(\n",
    "                                        \"source\",\n",
    "                                        'java',\n",
    "                                        problem_id,\n",
    "                                        closeJavaSolution,\n",
    "                                        functions_standalone_java,\n",
    "                                        functions_class_java,\n",
    "                                        closeSubmissionIdjava,\n",
    "                                        verdict_java\n",
    "                                    ).toJSON(),Solution(\n",
    "                                        \"source\",\n",
    "                                        'java',\n",
    "                                        problem_id,\n",
    "                                        acceptedJavaSolution,\n",
    "                                        functions_standalone_java,\n",
    "                                        functions_class_java,\n",
    "                                        submission_id_java,\n",
    "                                        \"Accepted\"\n",
    "                                    ).toJSON())\n",
    "                                )\n",
    "        #write in a file next task\n",
    "    write_output_to_file(java_solutions, \"java_solutions.jsonl\")\n",
    "    write_output_to_file(python_solutions, \"python_solutions.jsonl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in tqdm(list(data.keys())[:10]):\n",
    "    process_user(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(java_solutions))\n",
    "print(len(python_solutions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_solutions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat ../Project_CodeNet/data/p00220/Java/s289306249.java\n",
    "#cat ../Project_CodeNet/data/p00442/Java/s813585875.java\n",
    "from codegen.preprocessing.lang_processors.java_processor import JavaProcessor\n",
    "from codegen.preprocessing.lang_processors.python_processor import PythonProcessor\n",
    "\n",
    "root_folder = \"../third_party\"\n",
    "jprocessor = JavaProcessor(root_folder=root_folder)\n",
    "#sol = \"../Project_CodeNet/data/p00220/Java/s289306249.java\"\n",
    "#sol = \"exceptional_case.java\"\n",
    "sol = \"../Project_CodeNet/data/p04049/Java/s881422316.java\"\n",
    "\n",
    "with open(sol, 'r', encoding='utf8') as f:\n",
    "    code = f.read()\n",
    "    print(code.strip())\n",
    "    code_tokens_java = jprocessor.tokenize_code(code)\n",
    "    fn_standalone_java, fn_class_java = jprocessor.extract_functions(code_tokens_java)\n",
    "    print(fn_standalone_java, fn_class_java)\n",
    "    functions_standalone_java = [(jprocessor.get_function_name(fn), fn) for fn in fn_standalone_java]\n",
    "    functions_class_java = [(jprocessor.get_function_name(fn), fn) for fn in fn_class_java]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exceptional_case.java', 'r', encoding='utf8') as f:\n",
    "    code = f.read()\n",
    "    print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"python_solutions.jsonl\", 'r') as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "        pprint(ex[1])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp ../Project_CodeNet/data/p00220/Java/s289306249.java exceptional_case.java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "with open(\"exceptional.jsonl\", 'r') as f:\n",
    "    for line in f:\n",
    "        #print(line.replace(\"\\'\",\"\\\"\"))\n",
    "        ex = json.loads(line.replace(\"\\'\",\"\\\"\"))\n",
    "        pprint(ex)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(data, path):\n",
    "    a_file = open(path, \"w\")\n",
    "    json.dump(data, a_file)\n",
    "    a_file.close()\n",
    "dt = {\n",
    "    'key':'val',\n",
    "    'key1':'va\"aba\"bl',\n",
    "}\n",
    "write([dt, dt], \"excep.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "java_data = getJsonData('../data/java/jsons/0.json')\n",
    "#python_data = getJsonData('../data/Python/jsons/0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(java_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in java_data:\n",
    "    print(val[0]['code_tokens'])\n",
    "    print(\"################\")\n",
    "    print(val[1]['code_tokens'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "from multiprocessing import Process, Lock\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import threading\n",
    "\n",
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "data = getJsonData(\"processed.json\")\n",
    "ans = 0\n",
    "for user in tqdm(data.keys()):\n",
    "    for problem_id in data[user].keys():\n",
    "        ans+=len(data[user][problem_id])\n",
    "print(\"total data = \", ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from difflib import SequenceMatcher\n",
    "from codegen.preprocessing.lang_processors.java_processor import JavaProcessor\n",
    "from codegen.preprocessing.lang_processors.python_processor import PythonProcessor\n",
    "import timeout_decorator \n",
    " \n",
    "\n",
    "root_folder = \"../third_party\"\n",
    "jprocessor = JavaProcessor(root_folder=root_folder)\n",
    "pyprocessor = PythonProcessor(root_folder=root_folder)\n",
    "\n",
    "class Solution:\n",
    "    def __init__(\n",
    "            self,\n",
    "            source,\n",
    "            lang,\n",
    "            problem_id,\n",
    "            code_tokens,\n",
    "            functions_standalone=[],\n",
    "            functions_class=[],\n",
    "            submission_id=\"\",\n",
    "            verdict=\"\"\n",
    "    ):\n",
    "        self.source = source\n",
    "        self.lang = lang\n",
    "        self.problem_id = problem_id\n",
    "        self.code_tokens = code_tokens.replace(\"\\\"\", \"\")\n",
    "        self.submission_id = submission_id\n",
    "        self.functions_standalone = functions_standalone\n",
    "        self.functions_class = functions_class\n",
    "        self.verdict=verdict\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'source: ' + self.source + '\\n' + \\\n",
    "               'lang: ' + self.lang + '\\n' + \\\n",
    "               'problem_id: ' + self.problem_id + '\\n' + \\\n",
    "               'code: ' + self.code_tokens + '\\n' + \\\n",
    "               'submission_id: ' + self.submission_id + '\\n' + \\\n",
    "               'verdict: ' + self.verdict + '\\n'\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'source: ' + self.source + '\\n' + \\\n",
    "               'lang: ' + self.lang + '\\n' + \\\n",
    "               'problem_id: ' + self.problem_id + '\\n' + \\\n",
    "               'code: ' + self.code_tokens + '\\n' + \\\n",
    "               'submission_id: ' + self.submission_id + '\\n'+ \\\n",
    "               'verdict: ' + self.verdict + '\\n'\n",
    "    def toJSON(self):\n",
    "        return self.__dict__\n",
    "\n",
    "@timeout_decorator.timeout(0.2) \n",
    "def calculate_similarity(code1_tokens, code2_tokens):\n",
    "    code1 = ' '.join(code1_tokens)\n",
    "    code2 = ' '.join(code2_tokens)\n",
    "    return SequenceMatcher(None, code1, code2).ratio()\n",
    "\n",
    "#Lock = threading.Lock()\n",
    "\n",
    "def write_output_to_file(problems, file_to_write):\n",
    "    Lock.acquire()\n",
    "    mode = 'w'\n",
    "    if os.path.exists(file_to_write):\n",
    "        mode = 'a'\n",
    "        with open(file_to_write, mode, encoding='utf8') as fw:\n",
    "            fw.write('\\n')\n",
    "    with open(file_to_write, mode, encoding='utf8') as fw:\n",
    "        fw.write('\\n'.join([json.dumps(p) for p in problems]))\n",
    "    Lock.release()\n",
    "\n",
    "java_file_id = 0\n",
    "python_file_id = 0\n",
    "java_solutions = []\n",
    "python_solutions = []\n",
    "\n",
    "def write_output_to_json_file(file_name, one_example):\n",
    "    global java_solutions\n",
    "    global python_solutions\n",
    "    global java_file_id\n",
    "    global python_file_id\n",
    "    #global Lock\n",
    "    if(file_name =='Java'):\n",
    "        #Lock.acquire()\n",
    "        java_solutions.append(one_example)\n",
    "        #print(\"java len\", len(java_solutions))\n",
    "        if(len(java_solutions)==10000):\n",
    "            pth = '../data/Java/jsons/{}.json'.format(java_file_id)\n",
    "            with open(pth, 'w+', encoding=\"utf8\") as f:\n",
    "                json.dump(java_solutions, f)\n",
    "            java_solutions=[]\n",
    "            java_file_id+=1\n",
    "        #Lock.release()\n",
    "    if(file_name=='Python'):\n",
    "        #Lock.acquire()\n",
    "        #print(\"python len\", len(python_solutions))\n",
    "        python_solutions.append(one_example)\n",
    "        if(len(python_solutions)==10000):\n",
    "            pth = '../data/Python/jsons/{}.json'.format(python_file_id)\n",
    "            with open(pth, 'w+', encoding=\"utf8\") as f:\n",
    "                json.dump(python_solutions, f)\n",
    "            python_solutions=[]\n",
    "            python_file_id+=1\n",
    "        #Lock.release()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def process_user(user_id):\n",
    "\n",
    "    for problem_id in data[user_id].keys():\n",
    "        print(\"problem id = \", problem_id)\n",
    "        submissions = data[user_id][problem_id]\n",
    "\n",
    "        acceptedJavaSolution = \"\"\n",
    "        closeJavaSolution = \"\"\n",
    "        acceptedPythonSolution = \"\"\n",
    "        closePythonSolution = \"\"\n",
    "\n",
    "        functions_standalone_py=[]\n",
    "        functions_class_py = []\n",
    "        functions_standalone_java=[]\n",
    "        functions_class_java = []\n",
    "\n",
    "        closeSubmissionIdpy = \"\"\n",
    "        closeSubmissionIdjava=\"\"\n",
    "        submission_id_py=\"\"\n",
    "        submission_id_java=\"\"\n",
    "        verdict_py=\"\"\n",
    "        verdict_java=\"\"\n",
    "\n",
    "        for submisson in submissions:\n",
    "            try:\n",
    "                #print(\"in submission 152\")\n",
    "                if(submisson[2]==\"Java\"):\n",
    "                    if(submisson[5]==\"Accepted\"):\n",
    "                        solution_path = \"../Project_CodeNet/data/\"+problem_id+\"/Java/\"+submisson[0]+'.java'\n",
    "                        with open(solution_path, 'r', encoding='utf8') as f:\n",
    "                            code = f.read()\n",
    "                            acceptedJavaSolution = code[::]\n",
    "                            submission_id_java = submisson[0]\n",
    "                            #code_tokens_java = jprocessor.tokenize_code(code)\n",
    "                            #fn_standalone_java, fn_class_java = jprocessor.extract_functions(code_tokens_java)\n",
    "                            #functions_standalone_java = [(jprocessor.get_function_name(fn), fn) for fn in fn_standalone_java]\n",
    "                            #functions_class_java = [(jprocessor.get_function_name(fn), fn) for fn in fn_class_java]\n",
    "\n",
    "\n",
    "                if(submisson[2]==\"Python\"):\n",
    "                    if(submisson[5]==\"Accepted\"):\n",
    "                        solution_path = \"../Project_CodeNet/data/\"+problem_id+\"/Python/\"+submisson[0]+'.py'\n",
    "                        with open(solution_path, 'r', encoding='utf8') as f:\n",
    "                            code = f.read()\n",
    "                            acceptedPythonSolution = code[::]\n",
    "                            submission_id_py = submisson[0]\n",
    "                            #code_tokens_py = pyprocessor.tokenize_code(code)\n",
    "                            #fn_standalone_py, fn_class_py = pyprocessor.extract_functions(code_tokens_py)\n",
    "                            #functions_standalone_py = [(pyprocessor.get_function_name(fn), fn) for fn in fn_standalone_py]\n",
    "                            #functions_class_py = [(pyprocessor.get_function_name(fn), fn) for fn in fn_class_py]\n",
    "            except BaseException as error:\n",
    "                print(\"error for submission top problem id\",problem_id, submisson)\n",
    "                pass\n",
    "        \n",
    "        java_min_distance = 999999\n",
    "        python_min_distance = 999999\n",
    "        \n",
    "        for submisson in submissions:\n",
    "            #print(\"in submission 185 submission id:\", submisson)\n",
    "            try:\n",
    "                if(submisson[2]==\"Java\"):\n",
    "                    if(submisson[5]!=\"Accepted\"):\n",
    "                        solution_path = \"../Project_CodeNet/data/\"+problem_id+\"/Java/\"+submisson[0]+'.java'\n",
    "                        with open(solution_path, 'r', encoding='utf8') as f:\n",
    "                            code = f.read()\n",
    "                            dis = calculate_similarity(code,acceptedJavaSolution)\n",
    "                            if(dis<java_min_distance):\n",
    "                                closeJavaSolution=code[::]\n",
    "                                java_min_distance = dis\n",
    "                                closeSubmissionIdjava = submisson[0]\n",
    "                                verdict_java=submisson[5]\n",
    "\n",
    "\n",
    "                if(submisson[2]==\"Python\"):\n",
    "                    if(submisson[5]!=\"Accepted\"):\n",
    "                        solution_path = \"../Project_CodeNet/data/\"+problem_id+\"/Python/\"+submisson[0]+'.py'\n",
    "                        with open(solution_path, 'r', encoding='utf8') as f:\n",
    "                            code = f.read()\n",
    "                            dis = calculate_similarity(code,acceptedPythonSolution)\n",
    "                            if(dis<python_min_distance):\n",
    "                                closePythonSolution=code[::]\n",
    "                                python_min_distance = dis\n",
    "                                closeSubmissionIdpy = submisson[0]\n",
    "                                verdict_py=submisson[5]\n",
    "            except BaseException as error:\n",
    "                print(\"error for submission \", submisson)\n",
    "                pass\n",
    "\n",
    "        if(len(acceptedPythonSolution)*len(closePythonSolution)):  \n",
    "            write_output_to_json_file(\"Python\",(Solution(\n",
    "                                        \"source\",\n",
    "                                        'python',\n",
    "                                        problem_id,\n",
    "                                        closePythonSolution,\n",
    "                                        functions_standalone_py,\n",
    "                                        functions_class_py,\n",
    "                                        closeSubmissionIdpy,\n",
    "                                        verdict_py\n",
    "                                    ).toJSON(),Solution(\n",
    "                                        \"source\",\n",
    "                                        'python',\n",
    "                                        problem_id,\n",
    "                                        acceptedPythonSolution,\n",
    "                                        functions_standalone_py,\n",
    "                                        functions_class_py,\n",
    "                                        submission_id_py,\n",
    "                                        \"Accepted\"\n",
    "                                    ).toJSON())\n",
    "                                )\n",
    "        if(len(acceptedJavaSolution)*len(closeJavaSolution)):\n",
    "            write_output_to_json_file(\"Java\", (Solution(\n",
    "                                        \"source\",\n",
    "                                        'java',\n",
    "                                        problem_id,\n",
    "                                        closeJavaSolution,\n",
    "                                        functions_standalone_java,\n",
    "                                        functions_class_java,\n",
    "                                        closeSubmissionIdjava,\n",
    "                                        verdict_java\n",
    "                                    ).toJSON(),Solution(\n",
    "                                        \"source\",\n",
    "                                        'java',\n",
    "                                        problem_id,\n",
    "                                        acceptedJavaSolution,\n",
    "                                        functions_standalone_java,\n",
    "                                        functions_class_java,\n",
    "                                        submission_id_java,\n",
    "                                        \"Accepted\"\n",
    "                                    ).toJSON())\n",
    "                                )\n",
    "        #write in a file next task\n",
    "    '''\n",
    "    if(len(java_solutions)):\n",
    "        write_output_to_file(java_solutions, \"java_solutions.jsonl\")\n",
    "    if(len(python_solutions)):\n",
    "        write_output_to_file(python_solutions, \"python_solutions.jsonl\")\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_user('u326609687')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['u326609687']['p02574']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['u326609687']['p02574']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat ../Project_CodeNet/data/p02574/Python/s422117152.py\n",
    "!cat ../Project_CodeNet/data/p02575/Python/s428831120.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../codet5/tensorboard/home/mahim/program_repair/CodeNet/codet5/codenet/java2java/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codet5/tensorboard/home/mahim/program_repair/CodeNet/codet5/codenet/java2j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/mahim/program_repair/CodeNet/data/java/processed/test.jsonl\", encoding=\"utf8\") as f:\n",
    "    data = json.load(f)\n",
    "    #print(len(data))\n",
    "    print(data[0].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "from multiprocessing import Process, Lock\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "data = getJsonData(\"processed.json\")\n",
    "ans = 0\n",
    "for user in tqdm(data.keys()):\n",
    "    for problem_id in data[user].keys():\n",
    "        ans+=len(data[user][problem_id])\n",
    "print(\"total data = \", ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "Problem_count = 0\n",
    "\n",
    "lang_count = 0\n",
    "path_sum = 0\n",
    "solved_be_user = 0\n",
    "\n",
    "path_lengths = []\n",
    "submission_counts = []\n",
    "lang_counts = []\n",
    "for user in tqdm(list(data.keys())):\n",
    "    language_lst=set()\n",
    "    submission_count = 0\n",
    "    for problem_id in data[user].keys():\n",
    "        path_len = 0\n",
    "        if(len(data[user][problem_id])):\n",
    "            Problem_count+=1\n",
    "        \n",
    "        langs = {}\n",
    "        for idx, subs in enumerate(data[user][problem_id]):\n",
    "            # need to consider for each language\n",
    "            if subs[2] in langs.keys():\n",
    "                langs[subs[2]].append(subs)\n",
    "            else:\n",
    "                langs[subs[2]] = [subs]\n",
    "            language_lst.add(subs[2])\n",
    "            submission_count+=1\n",
    "        \n",
    "        # Path sum calculation\n",
    "        for lang in langs:\n",
    "            first_wa = 0\n",
    "            first_ac = -1\n",
    "            for idx, sub in enumerate(sorted(langs[lang], key=lambda x: x[1])):\n",
    "                if(sub[-1]==\"Accepted\"):\n",
    "                    first_ac = max(first_ac, idx)\n",
    "                else:\n",
    "                    first_wa = min(first_wa, idx)\n",
    "        \n",
    "            if(first_ac-first_wa+1>0):\n",
    "                #print(langs[lang])\n",
    "                #print(first_ac-first_wa)    \n",
    "                path_sum+=first_ac-first_wa+1\n",
    "                solved_be_user+=1\n",
    "                path_lengths.append(first_ac-first_wa+1)\n",
    "\n",
    "            \n",
    "    lang_count+=len(language_lst)\n",
    "    lang_counts.append(len(language_lst))\n",
    "    submission_counts.append(submission_count)\n",
    "        \n",
    "    #break\n",
    "print(\"per user average submission count\", sum(submission_counts)/len(data))\n",
    "print(\"per user average language usage count\", lang_count/len(data))\n",
    "print(\"per user average accepted path length\", path_sum/solved_be_user)\n",
    "'''\n",
    "per user average submission count 90.26494052329126\n",
    "per user average language usage count 1.4337000090804135\n",
    "per user average accepted path length 1.9145810148516795\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins=10\n",
    "n, bins, patches = plt.hist(path_lengths, bins=[i for i in range(11)])\n",
    "ticks = [(patch._x0 + patch._x1)/2 for patch in patches]\n",
    "ticklabels = [i for i in range(n_bins)]\n",
    "plt.xticks(ticks, ticklabels)\n",
    "plt.xlabel(\"Number of submissions before accepted\")\n",
    "plt.ylabel(\"Number of users\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins=10\n",
    "n, bins, patches = plt.hist(lang_counts, bins=[i for i in range(11)])\n",
    "ticks = [(patch._x0 + patch._x1)/2 for patch in patches]\n",
    "ticklabels = [i for i in range(n_bins)]\n",
    "plt.xticks(ticks, ticklabels)\n",
    "plt.xlabel(\"Number of Languages used by a user\")\n",
    "plt.ylabel(\"Number of users\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n, bins, patches = plt.hist(submission_counts, bins=[i for i in range(200)])\n",
    "#ticks = [(patch._x0 + patch._x1)/2 for patch in patches]\n",
    "#ticklabels = [i for i in range(n_bins)]\n",
    "#plt.xticks(ticks, ticklabels)\n",
    "plt.xlabel(\"Number of Submissons per user\")\n",
    "plt.ylabel(\"Number of users\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_counts[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "\n",
    "files = \"../data/java/jsons/\"\n",
    "src_sizes = []\n",
    "tgt_sizes = []\n",
    "for file in glob(files+'*.json'):\n",
    "    print(file)\n",
    "    with open(file, 'r') as f:\n",
    "        temp = json.load(f)\n",
    "        for ex in temp:\n",
    "            src_sizes.append(len(ex[0]['code_tokens']))\n",
    "            tgt_sizes.append(len(ex[1]['code_tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(src_sizes, bins=[i for i in range(0, 10000, 1000)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../../BIFI/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "data = getJsonData(\"../../BIFI/data/orig_bad_code/orig.bad.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "for key in list(data.keys())[:2]:\n",
    "    pprint(data[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "file = \"../data/java/processed/train.jsonl\"\n",
    "\n",
    "with open(file, 'r') as f:\n",
    "    train = json.load(f)\n",
    "print(len(train))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "def calculate_similarity(code1_tokens, code2_tokens):\n",
    "    code1 = ' '.join(code1_tokens)\n",
    "    code2 = ' '.join(code2_tokens)\n",
    "    return SequenceMatcher(None, code1, code2).ratio()\n",
    "dis = []\n",
    "for dt in tqdm(train):\n",
    "    dis.append(calculate_similarity(dt['src'], dt['tgt']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(dis, bins=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "problem_desc = []\n",
    "for file in glob(\"../Project_CodeNet/problem_descriptions/*html\"):\n",
    "    problem_desc.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_desc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    from BeautifulSoup import BeautifulSoup\n",
    "except ImportError:\n",
    "    from bs4 import BeautifulSoup\n",
    "Base_link = \"https://www.dropbox.com/sh/nx3tnilzqz7df8a/AAAYlTq2tiEHl5hsESw6-yfLa?dl=0\"\n",
    "import requests\n",
    "req = requests.get(Base_link)\n",
    "#print(html)\n",
    "soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "for a in soup.find_all('a', href=True):\n",
    "    print(\"Found the URL:\", a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Access_token = \"sl.BBQsZOVExLY-32FcgPQGwk5yMVeJCjShnddXfJGjzAnj0CQ-5GlVrRO39hPX7lP6BnpyFw1_3pE7wPwWsorCjTSwTRRiBqMkGB2q1KMmjPgrD78wu2lHpbrPA_xRQlWZ42oxz2o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = \"https://www.dropbox.com/sh/nx3tnilzqz7df8a/.*/.*dl=0\"\n",
    "\n",
    "re.findall(r'{}'.format(pattern),req.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def download_and_extract(lnk):\n",
    "    lnk = lnk.replace(\"?dl=0\", \"?dl=1\")\n",
    "    name = lnk.split(\"/\")[-1]\n",
    "    name = name.split(\"?dl=1\")[0]+\".zip\"\n",
    "    #print(name)\n",
    "    subprocess.run([\"wget\", \"-O\", name, lnk])\n",
    "    subprocess.run([\"unzip\",name ,\"-d\",\"atcoder_test_cases/\"+name.replace(\".zip\", \"\")])\n",
    "    subprocess.run([\"rm\" ,\"-rf\",name])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "with open(\"atcoder_links.txt\") as f:\n",
    "    links = f.readlines()\n",
    "for link in tqdm(links):\n",
    "    download_and_extract(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "problemlist=pd.read_csv(\"../Project_CodeNet/metadata/problem_list.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "problems = defaultdict(list)\n",
    "for index, row in tqdm(problemlist.iterrows()):\n",
    "    if(row['dataset']=='AtCoder'):\n",
    "        if(\"AtCoder Regular Contest\" in row['name']):\n",
    "            number = row['name'].split(\" \")[3]\n",
    "            problems[\"ARC\"+number].append(row['id'])\n",
    "        if(\"AtCoder Beginner Contest\" in row['name']):\n",
    "            number = row['name'].split(\" \")[3]\n",
    "            problems[\"ABC\"+number].append(row['id'])\n",
    "        if(\"AtCoder Grand Contest\" in row['name']):\n",
    "            number = row['name'].split(\" \")[3]\n",
    "            problems[\"AGC\"+number].append(row['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "folders = glob(\"atcoder_test_cases/*\")\n",
    "\n",
    "final_keys = []\n",
    "for idx in range(len(folders)):\n",
    "    folders[idx] = folders[idx].replace(\"atcoder_test_cases/\", \"\")\n",
    "#print(folders)\n",
    "for key in problems.keys():\n",
    "    if key in folders:\n",
    "        if len(problems[key]) == len(glob(\"atcoder_test_cases/\"+key+\"/*\")):\n",
    "            final_keys.append(key)\n",
    "            \n",
    "    elif key.lower() in folders :\n",
    "        if len(problems[key]) == len(glob(\"atcoder_test_cases/\"+ key.lower() +\"/*\")):\n",
    "            final_keys.append(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problemid_to_tc = {}\n",
    "for key in problems:\n",
    "    if(key in final_keys):\n",
    "        for idx, prob_id in enumerate(problems[key]):\n",
    "            folder_list = glob(\"atcoder_test_cases/\"+key+\"/*\")\n",
    "            if(len(folder_list)==0):\n",
    "                folder_list = glob(\"atcoder_test_cases/\"+key.lower()+\"/*\")\n",
    "            problemid_to_tc[prob_id] = folder_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(problemid_to_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "from multiprocessing import Process, Lock\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "data = getJsonData(\"../data/java/processed/test.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[0]\n",
    "#def run_and_report()\n",
    "\n",
    "#st = \"atcoder_test_cases/ABC118/B/in/3_mmin_1\"\n",
    "#out = st.split(\"/\")\n",
    "#out[3] = \"out\"\n",
    "#\"/\".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codegen.preprocessing.lang_processors.java_processor import JavaProcessor\n",
    "from codegen.preprocessing.lang_processors.python_processor import PythonProcessor\n",
    "import subprocess\n",
    "import filecmp\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import sys\n",
    "\n",
    "def check_floating(n1, n2):\n",
    "    n1 = n1.replace(\"-\", \"\").replace(\"+\", \"\")\n",
    "    n2 = n2.replace(\"-\", \"\").replace(\"+\", \"\")\n",
    "    \n",
    "    if (not n1.replace('.','',1).replace(\"E\",\"\").isdigit()) or (not n1.replace('.','',1).replace(\"E\",\"\").isdigit()):\n",
    "        return False\n",
    "    if abs(float(n1)-float(n2))<1e8:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def print_error(l1, l2):\n",
    "    print(\"###\")\n",
    "    print(l1)\n",
    "    print(\"###\")\n",
    "    print(l2)\n",
    "    print(\"###\")\n",
    "\n",
    "def compare_files(file1, file2):\n",
    "    with open(file1) as f1, open(file2) as f2: \n",
    "        content1 = f1.read().split()\n",
    "        content2 = f2.read().split()\n",
    "\n",
    "        for l1, l2 in zip(content1, content2):\n",
    "            if l1.strip() != l2.strip(): \n",
    "                num1s = l1.strip().split(\" \")\n",
    "                num2s = l2.strip().split(\" \")\n",
    "                if(len(num1s) == len(num2s)):\n",
    "                    for idx in range(len(num1s)):\n",
    "                        if not check_floating(num1s[idx],num2s[idx]):\n",
    "                            print_error(l1, l2)\n",
    "                            return False\n",
    "                else:\n",
    "                    print_error(l1, l2)\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "root_folder = \"../third_party\"\n",
    "jprocessor = JavaProcessor(root_folder=root_folder)\n",
    "\n",
    "uniq = set()\n",
    "\n",
    "#code_tokens_java = jprocessor.tokenize_code(code)\n",
    "cnt = 0\n",
    "done = False\n",
    "for dt in tqdm(data[12475:]): #12480+721 14975\n",
    "    if dt['id'].split(\"_\")[0] in problemid_to_tc.keys():\n",
    "        #if(dt['tgt_id'].split(\"_\")[1] != \"s473235135\"):\n",
    "        #    continue\n",
    "        cnt+=1\n",
    "        #print(\"comes\")\n",
    "        #print(dt['id'])\n",
    "        #pprint(dt)\n",
    "        #print(dt['src'])\n",
    "        code = jprocessor.detokenize_code(dt['tgt'])\n",
    "        if dt['tgt_id'] in uniq:\n",
    "            continue\n",
    "        uniq.add(dt['tgt_id'])\n",
    "        with open('Main.java', 'w', encoding='utf8') as fw:\n",
    "            fw.write(code)\n",
    "        test_case_folder = problemid_to_tc[dt['id'].split(\"_\")[0]]\n",
    "        in_files = glob(test_case_folder+\"/in/*\")\n",
    "        p1 = subprocess.run([\"javac\",\"Main.java\"])\n",
    "        return_code = p1.returncode\n",
    "\n",
    "        if(return_code):\n",
    "            print(\"######## doesnt compile  ############\")\n",
    "            print(p1.stderr.decode(\"utf-8\")) 14975\n",
    "            print(dt['tgt_id'])\n",
    "            #pprint(dt)\n",
    "            #doesn't compile correctly\n",
    "\n",
    "        for in_file in in_files:\n",
    "            #subprocess.run([\"java\",\"Main\" ,\"<\",in_files[0], \">\", \"cmd_out.txt\"], shell=True)\n",
    "            cmd = \"java Main < {} > cmd_out.txt\".format(in_file)\n",
    "            p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)\n",
    "            p.wait()\n",
    "            #output = p.stdout\n",
    "            #print(output)\n",
    "            out = in_file.split(\"/\")\n",
    "            out[3] = \"out\"\n",
    "            out_file =\"/\".join(out)\n",
    "            out_file = out_file.replace(\".in\", \".out\")\n",
    "\n",
    "            p2 = subprocess.Popen([\"cp\",out_file, \"cmd_out_match.txt\"])\n",
    "            p2.wait()\n",
    "            #match \n",
    "            #print(filecmp.cmp('cmd_out.txt', 'cmd_out_match.txt'))\n",
    "            if not compare_files('cmd_out.txt', 'cmd_out_match.txt'):\n",
    "                #done=True\n",
    "                print(dt['tgt_id'])\n",
    "                #break\n",
    "                print(in_file)\n",
    "        p3 = subprocess.run([\"rm\",\"Main.java\"])\n",
    "        p4 = subprocess.run([\"rm\",\"*.class\"])\n",
    "#print(cnt)\n",
    "\n",
    "#accept one valid way we need to skip those p02697,\n",
    "#used weird library runs on jdk 1.8 but not in jdk 11 p02682_s116318276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"p03334,p02678,p02690,p02692,p02697,p02850,p02825,p02902,p02903,p02976,p02977,p03097,p03938,p03245,p03044,p02972,p03263,p03836,p03267,p03257,p03394,p03952,p04007,p04035,p03746,p02963,p03095,p02669,p02825,p03046,p02997,p02936, p02694, p02975,p02731, p02861,p03110\"\n",
    "print(list(set(s.replace(\" \", \"\").split(\",\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = subprocess.Popen([\"javac\",\"Main.java\"])\n",
    "return_code = p1.wait()\n",
    "print(return_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"java Main < atcoder_test_cases/ABC138/D/in/b04 > cmd_out.txt\"\n",
    "p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=subprocess.DEVNULL, close_fds=True)\n",
    "p.wait()\n",
    "print(\"command exucuted\")\n",
    "\n",
    "in_file = \"atcoder_test_cases/ABC138/D/in/b04\"\n",
    "out = in_file.split(\"/\")\n",
    "out[3] = \"out\"\n",
    "out_file =\"/\".join(out)\n",
    "out_file = out_file.replace(\".in\", \".out\")\n",
    "\n",
    "p2 = subprocess.Popen([\"cp\",out_file, \"cmd_out_match.txt\"])\n",
    "p2.wait()\n",
    "print(\"Matching Files\")\n",
    "\n",
    "if not compare_files('cmd_out.txt', 'cmd_out_match.txt'):\n",
    "    #done=True\n",
    "    #print(dt['tgt_id'])\n",
    "    print(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One such Way p02678,p02690,p02692,p02697,p02850,p02825,p02902,p02903,p02976,p02977,p03097,p03938,p03245,p03044,p02972\n",
    "#One such way p03263,p03836,p03267,p03257,p03394,p03952,p04007,p04035,p03746,p02963,p03095,p02669,p02825,p03046,p02997\n",
    "\n",
    "# p02936, p02694 p02975 one after contest doesn't match\n",
    "#p02731 has higher thresholds for checking double value, p02861,p03110 as well\n",
    "\n",
    "'''\n",
    "Need to check \n",
    "\n",
    "p02912_s201342530\n",
    "atcoder_test_cases/ABC141/D/in/testcase_03.nkftmpjKHWPL\n",
    "this has one weird input which i deleted from the atcoder_testcases folder\n",
    "\n",
    "'''\n",
    "\n",
    "###\n",
    "#num1 = \"0.0000000000000001E-5\"\n",
    "#num2 = \"-0.0000000000000001E-5\"\n",
    "\n",
    "#num1 = \"1.1551382117326875E-5\"\n",
    "#num2 = \"0.00001155138223854135\\n\"\n",
    "\n",
    "###\n",
    "#756.26049783473536042289\n",
    "num1 = \"3.57508992E8\"\n",
    "###\n",
    "num2 = \"357508993.7616\"\n",
    "def only_digits(num):\n",
    "    return num.replace(\"-\", \"\").replace(\"+\", \"\").replace('.','',1).replace(\"E\",\"\").isdigit()\n",
    "\n",
    "def check_floating(n1, n2):\n",
    "    if (not only_digits(n1)) or (not only_digits(n2)):\n",
    "        return False\n",
    "    print(float(n1), float(n2))\n",
    "    if abs(float(n1)-float(n2))<1e-6:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "num1s = num1.strip().split(\" \")\n",
    "num2s = num2.strip().split(\" \")\n",
    "if(len(num1s) != len(num2s)):\n",
    "    print(\"Not equal\")\n",
    "for idx in range(len(num1s)):\n",
    "    print(check_floating(num1s[idx],num2s[idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(\"0.00001155138223854135\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_floating(n1, n2):\n",
    "    n1 = n1.replace(\"-\", \"\").replace(\"+\", \"\")\n",
    "    n2 = n2.replace(\"-\", \"\").replace(\"+\", \"\")\n",
    "    \n",
    "    if (not n1.replace('.','',1).replace(\"E\",\"\").isdigit()) or (not n1.replace('.','',1).replace(\"E\",\"\").isdigit()):\n",
    "        return False\n",
    "    if abs(float(n1)-float(n2))<1e8:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def print_error(l1, l2):\n",
    "    print(\"###\")\n",
    "    print(l1)\n",
    "    print(\"###\")\n",
    "    print(l2)\n",
    "    print(\"###\")\n",
    "\n",
    "def compare_files(file1, file2):\n",
    "    try:\n",
    "        with open(file1) as f1, open(file2) as f2: \n",
    "            content1 = f1.read().split()\n",
    "            content2 = f2.read().split()\n",
    "            for l1, l2 in zip(content1, content2):\n",
    "                if l1.strip() != l2.strip(): \n",
    "                    num1s = l1.strip().split(\" \")\n",
    "                    num2s = l2.strip().split(\" \")\n",
    "                    if(len(num1s) == len(num2s)):\n",
    "                        for idx in range(len(num1s)):\n",
    "                            if not check_floating(num1s[idx],num2s[idx]):\n",
    "                                print_error(l1, l2)\n",
    "                                return False\n",
    "                    else:\n",
    "                        print_error(l1, l2)\n",
    "                        return False\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(\"exception = \", e)\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head atcoder_test_cases/ABC157/A/out/01-handmade-01\n",
    "p02658_s473235135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm temp.java\n",
    "p03037_s170937198\n",
    "!cp ../Project_CodeNet/data/p02658/Java/s473235135.java temp2.java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_floating(n1, n2):\n",
    "    n1 = n1.replace(\"-\", \"\").replace(\"+\", \"\")\n",
    "    n2 = n2.replace(\"-\", \"\").replace(\"+\", \"\")\n",
    "    \n",
    "    if (not n1.replace('.','',1).replace(\"E\",\"\").isdigit()) or (not n1.replace('.','',1).replace(\"E\",\"\").isdigit()):\n",
    "        return False\n",
    "    if abs(float(n1)-float(n2))<1e-8:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def print_error(l1, l2):\n",
    "    print(\"###\")\n",
    "    print(l1)\n",
    "    print(\"###\")\n",
    "    print(l2)\n",
    "    print(\"###\")\n",
    "\n",
    "def compare_files(file1, file2):\n",
    "    with open(file1) as f1, open(file2) as f2: \n",
    "        content1 = f1.read().split()\n",
    "        content2 = f2.read().split()\n",
    "        #print(content1, content2)\n",
    "        for l1, l2 in zip(content1, content2):\n",
    "            print(l1.strip(), l2.strip(), l1.strip() != l2.strip())\n",
    "            if l1.strip() != l2.strip(): \n",
    "                num1s = l1.strip().split(\" \")\n",
    "                num2s = l2.strip().split(\" \")\n",
    "                if(len(num1s) == len(num2s)):\n",
    "                    for idx in range(len(num1s)):\n",
    "                        if not check_floating(num1s[idx],num2s[idx]):\n",
    "                            print_error(l1, l2)\n",
    "                            return False\n",
    "                else:\n",
    "                    print_error(l1, l2)\n",
    "                    return False\n",
    "        return True\n",
    "compare_files('cmd_out.txt', 'cmd_out_match.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = subprocess.Popen(\"javac Main.java\", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "print(\"wait result\", p1.wait())\n",
    "output,error=p1.communicate()\n",
    "print(\"###\")\n",
    "print(output)\n",
    "print(\"###\")\n",
    "print(error)\n",
    "print(\"####\")\n",
    "print(p1.returncode)\n",
    "\n",
    "\n",
    "cmd = \"java Main < {} > manual_check.txt\".format(\"atcoder_test_cases/ABC169/B/in/max_02.txt\")\n",
    "p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)\n",
    "p.wait()\n",
    "print(\"ok\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problemid_to_tc['p02677']\n",
    "ab = \"a string '' c\"\n",
    "nn = ab[::]\n",
    "print(nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp2.java\") as f:\n",
    "    fl = f.read()\n",
    "print(jprocessor.detokenize_code(jprocessor.tokenize_code(fl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "from multiprocessing import Process, Lock\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "data = getJsonData(\"processed.json\")\n",
    "ans = 0\n",
    "for user in tqdm(data.keys()):\n",
    "    for problem_id in data[user].keys():\n",
    "        #ans+=len(data[user][problem_id])\n",
    "        for sub in data[user][problem_id]:\n",
    "            if sub[0] == \"s116318276\":\n",
    "                print(user)\n",
    "                print(sub)\n",
    "print(\"total data = \", ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = getJsonData(\"../data/java/processed/test.jsonl\")\n",
    "#for dt in test:\n",
    "for user in tqdm(data.keys()):\n",
    "    for problem_id in data[user].keys():\n",
    "        for sub in data[user][problem_id]:\n",
    "            #print(sub)\n",
    "            if sub[0] == \"s116318276\":\n",
    "                print(user,problem_id,sub )\n",
    "                print(sub)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ze = getJsonData(\"../data/java/jsons/27.json\")\n",
    "for dt in ze:\n",
    "    if(len(dt)<2):\n",
    "        pprint(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for running java\n",
    "javac test_java.java \n",
    "java test_java < cmd_in.txt > cmd_out.txt\n",
    "\n",
    "for running python\n",
    "python3 test_py.py < cmd_in.txt > cmd_out.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "train = getJsonData(\"../data/java/processed/train.jsonl\")\n",
    "test = getJsonData(\"../data/java/processed/test.jsonl\")\n",
    "valid = getJsonData(\"../data/java/processed/valid.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "problems = set()\n",
    "for json in [train, test, valid]:\n",
    "    for dt in tqdm(json):\n",
    "        problems.add(dt['src_id'].split(\"_\")[0])\n",
    "#pprint(data[0]['src_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "processed = getJsonData(\"processed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "java = set()\n",
    "for key in tqdm(processed):\n",
    "    pprint(processed[key])\n",
    "    \n",
    "    for problem in processed[key]:\n",
    "        for sub in processed[key][problem]:\n",
    "            if 'Python' in sub[2]:\n",
    "                print(sub)\n",
    "                break\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(problems & java)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e03c7d5b0a8d68dab11758fee63a529a36735699315db70e30825a4f9c804d12"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('python36': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
